{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2eb52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from data_prep_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f866537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tickers = {\n",
    "    '30_year_bonds': 'TLT',\n",
    "    '10_year_bonds': 'IEF',\n",
    "    '5_year_bonds': 'IEI',\n",
    "    '2_year_bonds': 'SHY',\n",
    "    '1_year_bonds': 'SHV',\n",
    "    'gold': 'GLD',\n",
    "    'silver': 'SLV',\n",
    "    # 'copper': 'CPER', # starts in 2011\n",
    "    'oil': 'USO',\n",
    "    'natural_gas': 'UNG',\n",
    "    'sp500': 'SPY',\n",
    "    'nasdaq': 'QQQ',\n",
    "    'dow_jones': 'DIA',\n",
    "    'russell_2000': 'IWM',\n",
    "    'us_dollar': 'UUP',\n",
    "    'emerging_markets': 'EEM',\n",
    "    'euro': 'FXE',\n",
    "    'british_pound': 'FXB',\n",
    "    'japanese_yen': 'FXY',\n",
    "    # 'bitcoin': 'BTC-USD', # starts in 2014\n",
    "    # 'ethereum': 'ETH-USD', # start in 2014\n",
    "}\n",
    "\n",
    "target_tickers = {\n",
    "    'costco': 'COST',\n",
    "    # 'coinbase': 'COIN',\n",
    "    # 'robinhood': 'HOOD',\n",
    "    # 'amazon': 'AMZN',\n",
    "    # 'apple': 'AAPL',\n",
    "    # 'google': 'GOOGL',\n",
    "    # 'microsoft': 'MSFT',\n",
    "    # 'tesla': 'TSLA',\n",
    "    # 'meta': 'META',\n",
    "    # 'nvidia': 'NVDA',\n",
    "    # 'general_motors': 'GM',\n",
    "    # 'ford': 'F',\n",
    "    # 'crowdstrike': 'CRWD',\n",
    "    # 'palantir': 'PLTR',\n",
    "}\n",
    "\n",
    "START_DATE = '2010-01-01'\n",
    "END_DATE = '2025-06-20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864dbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fe9feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\saris\\OneDrive\\Desktop\\active inf investing\\src\\data_prep_utils.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start, end=end)\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num days in context_df: 3870\n",
      "Num days in target_df: 3870\n",
      "Num days in combined_df: 3870\n",
      "(3870, 234)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TLT_Close</th>\n",
       "      <th>TLT_High</th>\n",
       "      <th>TLT_Low</th>\n",
       "      <th>TLT_Open</th>\n",
       "      <th>TLT_Volume</th>\n",
       "      <th>TLT_EMA_12</th>\n",
       "      <th>TLT_EMA_26</th>\n",
       "      <th>TLT_MACD</th>\n",
       "      <th>TLT_Signal</th>\n",
       "      <th>TLT_BB_upper</th>\n",
       "      <th>...</th>\n",
       "      <th>FXY_Open</th>\n",
       "      <th>FXY_Volume</th>\n",
       "      <th>FXY_EMA_12</th>\n",
       "      <th>FXY_EMA_26</th>\n",
       "      <th>FXY_MACD</th>\n",
       "      <th>FXY_Signal</th>\n",
       "      <th>FXY_BB_upper</th>\n",
       "      <th>FXY_BB_lower</th>\n",
       "      <th>FXY_OBV</th>\n",
       "      <th>FXY_ATR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-12</th>\n",
       "      <td>87.169998</td>\n",
       "      <td>87.199997</td>\n",
       "      <td>86.599998</td>\n",
       "      <td>86.889999</td>\n",
       "      <td>43017800</td>\n",
       "      <td>85.930698</td>\n",
       "      <td>86.027221</td>\n",
       "      <td>-0.096523</td>\n",
       "      <td>-0.351946</td>\n",
       "      <td>87.170142</td>\n",
       "      <td>...</td>\n",
       "      <td>64.209999</td>\n",
       "      <td>219600</td>\n",
       "      <td>63.896924</td>\n",
       "      <td>63.825327</td>\n",
       "      <td>0.071597</td>\n",
       "      <td>0.102388</td>\n",
       "      <td>64.687385</td>\n",
       "      <td>63.104614</td>\n",
       "      <td>30394100.0</td>\n",
       "      <td>0.498571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-13</th>\n",
       "      <td>86.330002</td>\n",
       "      <td>86.879997</td>\n",
       "      <td>85.779999</td>\n",
       "      <td>86.730003</td>\n",
       "      <td>49374000</td>\n",
       "      <td>85.992129</td>\n",
       "      <td>86.049649</td>\n",
       "      <td>-0.057520</td>\n",
       "      <td>-0.293061</td>\n",
       "      <td>87.237552</td>\n",
       "      <td>...</td>\n",
       "      <td>63.810001</td>\n",
       "      <td>138700</td>\n",
       "      <td>63.915858</td>\n",
       "      <td>63.839747</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.097133</td>\n",
       "      <td>64.673140</td>\n",
       "      <td>63.190860</td>\n",
       "      <td>30255400.0</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-16</th>\n",
       "      <td>85.459999</td>\n",
       "      <td>86.430000</td>\n",
       "      <td>85.459999</td>\n",
       "      <td>86.080002</td>\n",
       "      <td>36496600</td>\n",
       "      <td>85.910263</td>\n",
       "      <td>86.005971</td>\n",
       "      <td>-0.095708</td>\n",
       "      <td>-0.253590</td>\n",
       "      <td>87.197879</td>\n",
       "      <td>...</td>\n",
       "      <td>64.029999</td>\n",
       "      <td>173500</td>\n",
       "      <td>63.864188</td>\n",
       "      <td>63.820507</td>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.086443</td>\n",
       "      <td>64.614042</td>\n",
       "      <td>63.295958</td>\n",
       "      <td>30081900.0</td>\n",
       "      <td>0.448571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17</th>\n",
       "      <td>86.500000</td>\n",
       "      <td>86.660004</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>34521600</td>\n",
       "      <td>86.000992</td>\n",
       "      <td>86.042566</td>\n",
       "      <td>-0.041574</td>\n",
       "      <td>-0.211187</td>\n",
       "      <td>87.292689</td>\n",
       "      <td>...</td>\n",
       "      <td>63.630001</td>\n",
       "      <td>128600</td>\n",
       "      <td>63.800467</td>\n",
       "      <td>63.793062</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.070635</td>\n",
       "      <td>64.628695</td>\n",
       "      <td>63.262304</td>\n",
       "      <td>29953300.0</td>\n",
       "      <td>0.446429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18</th>\n",
       "      <td>86.650002</td>\n",
       "      <td>87.089996</td>\n",
       "      <td>86.349998</td>\n",
       "      <td>86.879997</td>\n",
       "      <td>38589000</td>\n",
       "      <td>86.100839</td>\n",
       "      <td>86.087561</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>-0.166294</td>\n",
       "      <td>87.425877</td>\n",
       "      <td>...</td>\n",
       "      <td>63.599998</td>\n",
       "      <td>218500</td>\n",
       "      <td>63.745010</td>\n",
       "      <td>63.766909</td>\n",
       "      <td>-0.021899</td>\n",
       "      <td>0.052128</td>\n",
       "      <td>64.645143</td>\n",
       "      <td>63.215857</td>\n",
       "      <td>29734800.0</td>\n",
       "      <td>0.447143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TLT_Close   TLT_High    TLT_Low   TLT_Open  TLT_Volume  \\\n",
       "Date                                                                 \n",
       "2025-06-12  87.169998  87.199997  86.599998  86.889999    43017800   \n",
       "2025-06-13  86.330002  86.879997  85.779999  86.730003    49374000   \n",
       "2025-06-16  85.459999  86.430000  85.459999  86.080002    36496600   \n",
       "2025-06-17  86.500000  86.660004  85.750000  86.000000    34521600   \n",
       "2025-06-18  86.650002  87.089996  86.349998  86.879997    38589000   \n",
       "\n",
       "            TLT_EMA_12  TLT_EMA_26  TLT_MACD  TLT_Signal  TLT_BB_upper  ...  \\\n",
       "Date                                                                    ...   \n",
       "2025-06-12   85.930698   86.027221 -0.096523   -0.351946     87.170142  ...   \n",
       "2025-06-13   85.992129   86.049649 -0.057520   -0.293061     87.237552  ...   \n",
       "2025-06-16   85.910263   86.005971 -0.095708   -0.253590     87.197879  ...   \n",
       "2025-06-17   86.000992   86.042566 -0.041574   -0.211187     87.292689  ...   \n",
       "2025-06-18   86.100839   86.087561  0.013278   -0.166294     87.425877  ...   \n",
       "\n",
       "             FXY_Open  FXY_Volume  FXY_EMA_12  FXY_EMA_26  FXY_MACD  \\\n",
       "Date                                                                  \n",
       "2025-06-12  64.209999      219600   63.896924   63.825327  0.071597   \n",
       "2025-06-13  63.810001      138700   63.915858   63.839747  0.076111   \n",
       "2025-06-16  64.029999      173500   63.864188   63.820507  0.043682   \n",
       "2025-06-17  63.630001      128600   63.800467   63.793062  0.007405   \n",
       "2025-06-18  63.599998      218500   63.745010   63.766909 -0.021899   \n",
       "\n",
       "            FXY_Signal  FXY_BB_upper  FXY_BB_lower     FXY_OBV   FXY_ATR  \n",
       "Date                                                                      \n",
       "2025-06-12    0.102388     64.687385     63.104614  30394100.0  0.498571  \n",
       "2025-06-13    0.097133     64.673140     63.190860  30255400.0  0.471429  \n",
       "2025-06-16    0.086443     64.614042     63.295958  30081900.0  0.448571  \n",
       "2025-06-17    0.070635     64.628695     63.262304  29953300.0  0.446429  \n",
       "2025-06-18    0.052128     64.645143     63.215857  29734800.0  0.447143  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download and enrich data\n",
    "context_data = download_and_enrich_data(context_tickers, START_DATE, END_DATE)    \n",
    "context_df = pd.concat(context_data.values(), axis=1).dropna()\n",
    "target_data = download_and_enrich_data(target_tickers, START_DATE, END_DATE)    \n",
    "target_df = pd.concat(target_data.values(), axis=1).dropna()\n",
    "combined_df = pd.concat([context_df, target_df], axis=1).dropna()\n",
    "\n",
    "# verify timeframes\n",
    "# for ticker, df in context_data.items():\n",
    "#     print(f\"{ticker} index range: {df.index.min()} to {df.index.max()}\", 'count:', len(df))\n",
    "\n",
    "context_df.to_csv('../data/context_data.csv')\n",
    "combined_df.to_csv('../data/training_raw.csv')\n",
    "\n",
    "print('Num days in context_df:', len(context_df))\n",
    "print('Num days in target_df:', len(target_df))\n",
    "print('Num days in combined_df:', len(combined_df))\n",
    "print(context_df.shape)\n",
    "display(context_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00089227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader: 1736 samples\n",
      "Validation Loader: 243 samples\n",
      "Test Loader: 367 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define horizons for target predictions (trading days)\n",
    "horizons = {\"1_day\": 1, \"1_week\": 5, \"1_month\": 21, \"1_year\": 252}\n",
    "\n",
    "# Step 1: Create Target Columns\n",
    "def create_targets(df, target_column, horizons):\n",
    "    \"\"\"\n",
    "    Generate shifted target columns for specified horizons.\n",
    "    \"\"\"\n",
    "    for horizon, shift in horizons.items():\n",
    "        df[f\"Target_{horizon}\"] = df[target_column].shift(-shift)\n",
    "    return df\n",
    "\n",
    "# Step 2: Normalize Features\n",
    "def normalize_features(df, exclude_columns):\n",
    "    \"\"\"\n",
    "    Normalize input features using Min-Max scaling, excluding specified columns.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    input_features = df.drop(columns=exclude_columns)\n",
    "    scaled_features = scaler.fit_transform(input_features)\n",
    "    \n",
    "    # Reconstruct normalized DataFrame\n",
    "    normalized_df = pd.DataFrame(scaled_features, columns=input_features.columns, index=input_features.index)\n",
    "    for column in exclude_columns:\n",
    "        normalized_df[column] = df[column]  # Add back excluded columns (e.g., targets)\n",
    "    \n",
    "    return normalized_df, scaler\n",
    "\n",
    "# Step 3: Create Sequences for Transformer Input\n",
    "def create_sequences(data, target_columns, seq_length):\n",
    "    \"\"\"\n",
    "    Create sequences for transformer input with specified sequence length.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    data_values = data.drop(columns=target_columns).values\n",
    "    target_values = data[target_columns].values\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data_values[i:i + seq_length])\n",
    "        y.append(target_values[i + seq_length])\n",
    "    \n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Step 4: Custom Dataset for PyTorch\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Full Data Preparation Pipeline\n",
    "def prepare_data_pipeline(df, target_column, sequence_length=30):\n",
    "    \"\"\"\n",
    "    Prepare data for transformer input: normalize, create targets, and generate sequences.\n",
    "    \"\"\"\n",
    "    # Create targets\n",
    "    df = create_targets(df, target_column, horizons)\n",
    "\n",
    "    # Normalize features\n",
    "    exclude_columns = [f\"Target_{horizon}\" for horizon in horizons.keys()]\n",
    "    df, scaler = normalize_features(df, exclude_columns)\n",
    "\n",
    "    # Drop NaN values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Split data into training, validation, and test sets\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Create sequences\n",
    "    target_columns = exclude_columns\n",
    "    train_X, train_y = create_sequences(train_df, target_columns, sequence_length)\n",
    "    val_X, val_y = create_sequences(val_df, target_columns, sequence_length)\n",
    "    test_X, test_y = create_sequences(test_df, target_columns, sequence_length)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(StockDataset(train_X, train_y), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(StockDataset(val_X, val_y), batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(StockDataset(test_X, test_y), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, scaler\n",
    "\n",
    "# Example Usage\n",
    "# Assuming combined_df is the enriched DataFrame\n",
    "target_column = target_tickers['costco'] + \"_Close\"\n",
    "sequence_length = 256 # 21 = 1 month, 252 = 1 year\n",
    "\n",
    "# Prepare the data\n",
    "train_loader, val_loader, test_loader, scaler = prepare_data_pipeline(combined_df, target_column, sequence_length)\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "print(f\"Train Loader: {len(train_loader.dataset)} samples\")     \n",
    "print(f\"Validation Loader: {len(val_loader.dataset)} samples\")\n",
    "print(f\"Test Loader: {len(test_loader.dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe15da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb4447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
