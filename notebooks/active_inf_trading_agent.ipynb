{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f44633f",
   "metadata": {},
   "source": [
    "# Active Inference Portfolio Trading Agent\n",
    "\n",
    "This notebook implements an **Active Inference** agent for portfolio management over Bitcoin, Solana, Ethereum, SPY, and QQQ, using the same data pipeline as our DQN agent. It incorporates a **hyperbolic discounting** scheme (inspired by Paul Glimcher) in its expected free energy calculation. This is designed to showcase a principled neuro-inspired decision-making framework in a financial context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81d1e6",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Setup & Data Loading  \n",
    "2. Trading Environment  \n",
    "3. Active Inference Agent Architecture  \n",
    "4. Hyperbolic Discounting Function  \n",
    "5. Belief Updating & Policy Selection  \n",
    "6. Simulation & Performance Evaluation  \n",
    "7. Visualization of Beliefs & Allocations  \n",
    "8. Conclusions & Next Steps  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629a15fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saris\\AppData\\Local\\Temp\\ipykernel_38148\\841442458.py:40: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 2004-11-18 00:00:00 to 2025-07-08 00:00:00\n",
      "Features: 66 technical indicators\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup & Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Reuse technical indicators function from rl_trading_agent\n",
    "def calculate_technical_indicators(prices, volumes):\n",
    "    indicators = pd.DataFrame(index=prices.index)\n",
    "    windows = [7, 30, 90, 200, 365]\n",
    "    for t in prices.columns:\n",
    "        p = prices[t]; v = volumes[t]; r = p.pct_change().dropna()\n",
    "        for w in windows:\n",
    "            if len(p) >= w:\n",
    "                ma = p.rolling(w).mean()\n",
    "                vol_ma = v.rolling(w).mean()\n",
    "                vol_rolling = r.rolling(w).std() * np.sqrt(252)\n",
    "                indicators[f'{t}_price_ma_{w}'] = p / ma\n",
    "                indicators[f'{t}_sharpe_{w}'] = (r.rolling(w).mean() * 252) / (r.rolling(w).std() * np.sqrt(252))\n",
    "        delta = p.diff()\n",
    "        gain = delta.clip(lower=0).rolling(14).mean()\n",
    "        loss = (-delta).clip(lower=0).rolling(14).mean()\n",
    "        rs = gain / loss\n",
    "        indicators[f'{t}_rsi'] = 100 - (100 / (1 + rs))\n",
    "    return indicators.fillna(0)\n",
    "\n",
    "# Download price & volume data\n",
    "# tickers = ['BTC-USD','SOL-USD','ETH-USD','SPY','QQQ']\n",
    "tickers = ['QQQ', 'SPY', 'IWM', 'DIA', 'GLD', 'TLT']\n",
    "# start, end = '2017-01-01', datetime.today().strftime('%Y-%m-%d')\n",
    "start, end = '2002-01-01', datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "data = yf.download(tickers, start=start, end=end, progress=False)\n",
    "price_data = data['Close'].ffill().dropna()\n",
    "volume_data = data['Volume'].ffill().dropna()\n",
    "\n",
    "# Compute indicators\n",
    "tech_indicators = calculate_technical_indicators(price_data, volume_data)\n",
    "print(f\"Data from {price_data.index[0]} to {price_data.index[-1]}\")\n",
    "print(f\"Features: {tech_indicators.shape[1]} technical indicators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e5d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dim: (79,), Assets: ['DIA', 'GLD', 'IWM', 'QQQ', 'SPY', 'TLT']\n",
      "Sample state shape: 79\n",
      "Portfolio composition: {'cash': {'amount': 27.397260273972602, 'percentage': np.float64(100.0)}}\n"
     ]
    }
   ],
   "source": [
    "# 2. Trading Environment\n",
    "class TradingEnvironment:\n",
    "    def __init__(self, price_data, tech_ind, annual_investment=10000, tc=0.001):\n",
    "        self.p = price_data\n",
    "        self.tech = tech_ind\n",
    "        self.daily_cash = annual_investment / 365\n",
    "        self.tc = tc\n",
    "        self.tickers = price_data.columns.tolist()\n",
    "        self.n = len(self.tickers)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_idx = 0\n",
    "        self.cash = self.daily_cash\n",
    "        self.hold = np.zeros(self.n)\n",
    "        self.pv = 0\n",
    "        self.history = []\n",
    "        return self._state()\n",
    "\n",
    "    def _state(self):\n",
    "        if self.step_idx >= len(self.p):\n",
    "            return np.zeros(self._get_state_size())\n",
    "        \n",
    "        # Current prices (normalized)\n",
    "        prices = self.p.iloc[self.step_idx].values\n",
    "        norm = prices / prices.max()\n",
    "        \n",
    "        # Technical indicators\n",
    "        tech = self.tech.iloc[self.step_idx].values\n",
    "        \n",
    "        # Portfolio weights\n",
    "        total = self.cash + (self.hold * prices).sum()\n",
    "        weights = (self.hold * prices) / total if total > 0 else np.zeros(self.n)\n",
    "        cash_ratio = self.cash / total if total > 0 else 1.0\n",
    "        \n",
    "        return np.concatenate([norm, tech, weights, [cash_ratio]]).astype(np.float32)\n",
    "    \n",
    "    def _get_state_size(self):\n",
    "        return self.n + len(self.tech.columns) + self.n + 1\n",
    "    \n",
    "    def get_portfolio_composition(self):\n",
    "        if self.step_idx >= len(self.p):\n",
    "            return {'cash': {'amount': self.cash, 'percentage': 100}}\n",
    "        \n",
    "        prices = self.p.iloc[self.step_idx].values\n",
    "        total = self.cash + (self.hold * prices).sum()\n",
    "        \n",
    "        comp = {'cash': {'amount': self.cash, 'percentage': (self.cash/total*100) if total>0 else 0}}\n",
    "        \n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            if self.hold[i] > 0:\n",
    "                value = self.hold[i] * prices[i]\n",
    "                comp[ticker] = {\n",
    "                    'shares': self.hold[i],\n",
    "                    'value': value,\n",
    "                    'percentage': (value/total*100) if total>0 else 0\n",
    "                }\n",
    "        return comp\n",
    "\n",
    "    def step(self, acts):\n",
    "        if self.step_idx >= len(self.p) - 1:\n",
    "            return self._state(), 0, True, {}\n",
    "        \n",
    "        # Add daily investment\n",
    "        self.cash += self.daily_cash\n",
    "        \n",
    "        # Current prices\n",
    "        prices = self.p.iloc[self.step_idx].values\n",
    "        \n",
    "        # Execute actions (acts is a list of actions for each asset)\n",
    "        for i, act in enumerate(acts):\n",
    "            if act == 1:  # Buy\n",
    "                max_shares = self.cash / (prices[i] * (1 + self.tc))\n",
    "                shares_to_buy = min(max_shares, self.cash * 0.2 / prices[i])  # Max 20% per asset\n",
    "                cost = shares_to_buy * prices[i] * (1 + self.tc)\n",
    "                if cost <= self.cash and shares_to_buy > 0:\n",
    "                    self.hold[i] += shares_to_buy\n",
    "                    self.cash -= cost\n",
    "            elif act == 2:  # Sell\n",
    "                if self.hold[i] > 0:\n",
    "                    shares_to_sell = self.hold[i] * 0.2  # Sell 20%\n",
    "                    proceeds = shares_to_sell * prices[i] * (1 - self.tc)\n",
    "                    self.hold[i] -= shares_to_sell\n",
    "                    self.cash += proceeds\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        new_pv = self.cash + (self.hold * prices).sum()\n",
    "        reward = (new_pv - self.pv) / self.pv if self.pv > 0 else 0\n",
    "        self.pv = new_pv\n",
    "        self.history.append(new_pv)\n",
    "        \n",
    "        self.step_idx += 1\n",
    "        done = self.step_idx >= len(self.p) - 1\n",
    "        \n",
    "        return self._state(), reward, done, {}\n",
    "\n",
    "env = TradingEnvironment(price_data, tech_indicators)\n",
    "s0 = env.reset()\n",
    "print(f\"State dim: {s0.shape}, Assets: {env.tickers}\")\n",
    "print(f\"Sample state shape: {len(s0)}\")\n",
    "print(f\"Portfolio composition: {env.get_portfolio_composition()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421f6d2",
   "metadata": {},
   "source": [
    "## 3. Active Inference Agent Architecture\n",
    "\n",
    "We implement a simple **generative model** (p(o|s), p(s'|s,a)) and an **approximate posterior** (q(s|o)) using small neural networks. Decision making minimizes the **Expected Free Energy** under a **hyperbolic discount**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07dcff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9523809523809523, 0.8, 0.6666666666666666, 0.4]\n"
     ]
    }
   ],
   "source": [
    "# 4. Hyperbolic Discounting\n",
    "def hyperbolic_discount(t, k=0.01):\n",
    "    return 1.0/(1.0 + k*t)\n",
    "\n",
    "print([hyperbolic_discount(t,0.05) for t in [1,5,10,30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb6d3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Inference Agents initialized.\n",
      "State dim: 79, Assets: 6\n",
      "Neural network architecture:\n",
      "- Inference net: state -> latents\n",
      "- Observation model: latents -> observations\n",
      "- Transition model: (latents, action) -> next_latents\n"
     ]
    }
   ],
   "source": [
    "# 5. ActiveInferenceAgent\n",
    "class ActiveInferenceAgent:\n",
    "    def __init__(self, state_dim, n_assets, hidden=128, lr=1e-3, risk_lambda=0.0):\n",
    "        self.n_assets = n_assets\n",
    "        self.n_actions = 3  # hold, buy, sell\n",
    "        self.risk_lambda = risk_lambda\n",
    "        \n",
    "        # Inference network q(s|o)\n",
    "        self.inf_net = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden//2)\n",
    "        )\n",
    "        \n",
    "        # Observation model p(o|s)\n",
    "        self.obs_net = nn.Sequential(\n",
    "            nn.Linear(hidden//2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, state_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Transition model p(s'|s,a)\n",
    "        self.trans_net = nn.Sequential(\n",
    "            nn.Linear(hidden//2 + self.n_actions, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden//2)\n",
    "        )\n",
    "        \n",
    "        # Prior beliefs (learnable)\n",
    "        self.prior_mean = nn.Parameter(torch.zeros(hidden//2))\n",
    "        self.prior_logvar = nn.Parameter(torch.zeros(hidden//2))\n",
    "        \n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.inf_net.parameters()) + \n",
    "            list(self.obs_net.parameters()) + \n",
    "            list(self.trans_net.parameters()) +\n",
    "            [self.prior_mean, self.prior_logvar], lr=lr\n",
    "        )\n",
    "\n",
    "    def infer(self, state):\n",
    "        \"\"\"Infer latent state q(s|o)\"\"\"\n",
    "        return self.inf_net(torch.FloatTensor(state))\n",
    "\n",
    "    def predict_obs(self, latents):\n",
    "        \"\"\"Predict observations p(o|s)\"\"\"\n",
    "        return self.obs_net(latents)\n",
    "\n",
    "    def transition(self, latents, action_onehot):\n",
    "        \"\"\"Predict next latent state p(s'|s,a)\"\"\"\n",
    "        inp = torch.cat([latents, action_onehot], dim=-1)\n",
    "        return self.trans_net(inp)\n",
    "\n",
    "    def expected_free_energy(self, latents, candidate_action, t_step):\n",
    "        \"\"\"Calculate expected free energy for a candidate action\"\"\"\n",
    "        # One-hot encode action\n",
    "        a_onehot = torch.zeros(self.n_actions)\n",
    "        a_onehot[candidate_action] = 1.0\n",
    "        \n",
    "        # Predict next latent state\n",
    "        s_next = self.transition(latents, a_onehot)\n",
    "        \n",
    "        # Predict observation from next state\n",
    "        o_pred = self.predict_obs(s_next)\n",
    "        \n",
    "        # Reconstruction error (extrinsic value) - compare predicted obs with current obs\n",
    "        current_obs = self.predict_obs(latents)\n",
    "        recon_error = torch.mean((o_pred - current_obs.detach())**2)\n",
    "        \n",
    "        # Epistemic value (information gain)\n",
    "        epistemic = -torch.mean(s_next * torch.log(torch.abs(s_next) + 1e-8))\n",
    "        \n",
    "        # Risk penalty (variance of next state)\n",
    "        risk_penalty = self.risk_lambda * torch.var(s_next)\n",
    "        \n",
    "        # Apply hyperbolic discounting\n",
    "        discount = hyperbolic_discount(t_step)\n",
    "        \n",
    "        # Expected free energy\n",
    "        efe = discount * (recon_error + epistemic + risk_penalty)\n",
    "        \n",
    "        return efe\n",
    "\n",
    "    def act(self, state, t_step):\n",
    "        \"\"\"Choose action that minimizes expected free energy\"\"\"\n",
    "        latents = self.infer(state)\n",
    "        \n",
    "        # Calculate expected free energy for each action\n",
    "        free_energies = []\n",
    "        for action in range(self.n_actions):\n",
    "            fe = self.expected_free_energy(latents, action, t_step)\n",
    "            free_energies.append(fe)\n",
    "        \n",
    "        # Choose action with minimum expected free energy\n",
    "        best_action = torch.argmin(torch.stack(free_energies)).item()\n",
    "        \n",
    "        # Return action for each asset (could be sophisticated allocation)\n",
    "        # For simplicity, apply same action to all assets with some randomness\n",
    "        actions = []\n",
    "        for i in range(self.n_assets):\n",
    "            if np.random.random() < 0.7:  # 70% chance to use best action\n",
    "                actions.append(best_action)\n",
    "            else:\n",
    "                actions.append(np.random.randint(0, self.n_actions))  # Exploration\n",
    "        \n",
    "        return actions\n",
    "    \n",
    "    def update_beliefs(self, state, action, next_state, reward):\n",
    "        \"\"\"Update beliefs using variational inference\"\"\"\n",
    "        latents = self.infer(state)\n",
    "        next_latents = self.infer(next_state)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        obs_pred = self.predict_obs(latents)\n",
    "        recon_loss = F.mse_loss(obs_pred, torch.FloatTensor(state))\n",
    "        \n",
    "        # Transition loss\n",
    "        action_onehot = torch.zeros(self.n_actions)\n",
    "        if len(action) > 0:\n",
    "            action_onehot[action[0]] = 1.0  # Use first asset's action\n",
    "        \n",
    "        trans_pred = self.transition(latents, action_onehot)\n",
    "        trans_loss = F.mse_loss(trans_pred, next_latents.detach())\n",
    "        \n",
    "        # KL divergence with prior\n",
    "        kl_loss = torch.mean(\n",
    "            0.5 * (latents**2 - 2*torch.log(torch.abs(latents)+1e-8) - 1)\n",
    "        )\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = recon_loss + trans_loss + 0.1 * kl_loss\n",
    "        \n",
    "        # Update\n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return total_loss.item()\n",
    "\n",
    "# Create agents with different risk sensitivities\n",
    "agent_neutral = ActiveInferenceAgent(state_dim=len(s0), n_assets=len(tickers), risk_lambda=0.0)\n",
    "agent_averse = ActiveInferenceAgent(state_dim=len(s0), n_assets=len(tickers), risk_lambda=1.0)\n",
    "\n",
    "print(\"Active Inference Agents initialized.\")\n",
    "print(f\"State dim: {len(s0)}, Assets: {len(tickers)}\")\n",
    "print(\"Neural network architecture:\")\n",
    "print(\"- Inference net: state -> latents\")\n",
    "print(\"- Observation model: latents -> observations\") \n",
    "print(\"- Transition model: (latents, action) -> next_latents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430d20e",
   "metadata": {},
   "source": [
    "## 7. Visualization of Beliefs & Allocations\n",
    "\n",
    "- **Latent Beliefs** over time  \n",
    "- **Portfolio Value** & **Holdings** evolution  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82021b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE PORTFOLIO STRATEGY COMPARISON\n",
      "================================================================================\n",
      "Data Period: 2004-11-18 to 2025-07-08\n",
      "Assets: QQQ, SPY, IWM, DIA, GLD, TLT\n",
      "Annual Investment: $10,000 ($27.40 per day)\n",
      "Total Steps: 10,000 (with updates every 1,000 steps)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RUNNING SIMULATIONS...\n",
      "================================================================================\n",
      "\n",
      "=== EQUAL ALLOCATION STRATEGY ===\n",
      "Daily allocation per asset: $4.57\n",
      "  Step 0: PV=$54.74, Total Invested=$27.40\n",
      "    DIA: 16.7%\n",
      "    GLD: 16.7%\n",
      "    IWM: 16.7%\n",
      "  Step 1000: PV=$24477.77, Total Invested=$27424.66\n",
      "    GLD: 23.4%\n",
      "    TLT: 17.6%\n",
      "    DIA: 15.8%\n",
      "  Step 2000: PV=$81571.79, Total Invested=$54821.92\n",
      "    GLD: 24.0%\n",
      "    QQQ: 17.6%\n",
      "    DIA: 15.2%\n",
      "  Step 3000: PV=$144698.81, Total Invested=$82219.18\n",
      "    QQQ: 23.1%\n",
      "    SPY: 17.5%\n",
      "    IWM: 16.9%\n",
      "  Step 4000: PV=$293894.38, Total Invested=$109616.44\n",
      "    QQQ: 31.3%\n",
      "    SPY: 17.2%\n",
      "    DIA: 16.3%\n",
      "  Step 5000: PV=$480659.26, Total Invested=$137013.70\n",
      "    QQQ: 34.5%\n",
      "    SPY: 19.7%\n",
      "    DIA: 17.0%\n",
      "\n",
      "=== RISK-AVERSE AGENT ===\n",
      "Risk Lambda: 1.0\n",
      "  Step 0: PV=$54.75, FE=-0.0370, Loss=0.5286\n",
      "    cash: 26.3%\n",
      "    DIA: 19.9%\n",
      "    GLD: 16.2%\n",
      "\n",
      "=== RISK-AVERSE AGENT ===\n",
      "Risk Lambda: 1.0\n",
      "  Step 0: PV=$54.75, FE=-0.0370, Loss=0.5286\n",
      "    cash: 26.3%\n",
      "    DIA: 19.9%\n",
      "    GLD: 16.2%\n",
      "  Step 1000: PV=$23337.54, FE=0.0557, Loss=141.4269\n",
      "    DIA: 40.6%\n",
      "    GLD: 14.4%\n",
      "    TLT: 14.2%\n",
      "  Step 1000: PV=$23337.54, FE=0.0557, Loss=141.4269\n",
      "    DIA: 40.6%\n",
      "    GLD: 14.4%\n",
      "    TLT: 14.2%\n",
      "  Step 2000: PV=$69800.53, FE=0.0171, Loss=91.1101\n",
      "    DIA: 25.9%\n",
      "    cash: 20.6%\n",
      "    TLT: 16.5%\n",
      "  Step 2000: PV=$69800.53, FE=0.0171, Loss=91.1101\n",
      "    DIA: 25.9%\n",
      "    cash: 20.6%\n",
      "    TLT: 16.5%\n",
      "  Step 3000: PV=$108856.12, FE=0.0122, Loss=132.5367\n",
      "    GLD: 20.9%\n",
      "    DIA: 20.4%\n",
      "    QQQ: 15.2%\n",
      "  Step 3000: PV=$108856.12, FE=0.0122, Loss=132.5367\n",
      "    GLD: 20.9%\n",
      "    DIA: 20.4%\n",
      "    QQQ: 15.2%\n",
      "  Step 4000: PV=$182187.76, FE=0.0109, Loss=294.7079\n",
      "    cash: 42.2%\n",
      "    IWM: 22.0%\n",
      "    DIA: 16.2%\n",
      "  Step 4000: PV=$182187.76, FE=0.0109, Loss=294.7079\n",
      "    cash: 42.2%\n",
      "    IWM: 22.0%\n",
      "    DIA: 16.2%\n",
      "  Step 5000: PV=$267891.81, FE=0.0176, Loss=297.5124\n",
      "    DIA: 30.1%\n",
      "    TLT: 19.1%\n",
      "    QQQ: 16.2%\n",
      "  Step 5000: PV=$267891.81, FE=0.0176, Loss=297.5124\n",
      "    DIA: 30.1%\n",
      "    TLT: 19.1%\n",
      "    QQQ: 16.2%\n",
      "\n",
      "=== RISK-NEUTRAL AGENT ===\n",
      "Risk Lambda: 0.0\n",
      "  Step 0: PV=$54.78, FE=0.0171, Loss=0.5543\n",
      "    cash: 80.1%\n",
      "    TLT: 19.9%\n",
      "\n",
      "=== RISK-NEUTRAL AGENT ===\n",
      "Risk Lambda: 0.0\n",
      "  Step 0: PV=$54.78, FE=0.0171, Loss=0.5543\n",
      "    cash: 80.1%\n",
      "    TLT: 19.9%\n",
      "  Step 1000: PV=$24898.63, FE=-0.0026, Loss=141.3497\n",
      "    SPY: 24.1%\n",
      "    cash: 22.6%\n",
      "    GLD: 21.6%\n",
      "  Step 1000: PV=$24898.63, FE=-0.0026, Loss=141.3497\n",
      "    SPY: 24.1%\n",
      "    cash: 22.6%\n",
      "    GLD: 21.6%\n",
      "  Step 2000: PV=$75013.06, FE=0.0006, Loss=90.7303\n",
      "    TLT: 21.4%\n",
      "    IWM: 20.5%\n",
      "    DIA: 17.7%\n",
      "  Step 2000: PV=$75013.06, FE=0.0006, Loss=90.7303\n",
      "    TLT: 21.4%\n",
      "    IWM: 20.5%\n",
      "    DIA: 17.7%\n",
      "  Step 3000: PV=$116980.40, FE=0.0024, Loss=132.8992\n",
      "    cash: 53.9%\n",
      "    IWM: 15.0%\n",
      "    SPY: 13.6%\n",
      "  Step 3000: PV=$116980.40, FE=0.0024, Loss=132.8992\n",
      "    cash: 53.9%\n",
      "    IWM: 15.0%\n",
      "    SPY: 13.6%\n",
      "  Step 4000: PV=$190882.15, FE=0.0001, Loss=294.6774\n",
      "    QQQ: 22.2%\n",
      "    SPY: 20.2%\n",
      "    DIA: 19.1%\n",
      "  Step 4000: PV=$190882.15, FE=0.0001, Loss=294.6774\n",
      "    QQQ: 22.2%\n",
      "    SPY: 20.2%\n",
      "    DIA: 19.1%\n",
      "  Step 5000: PV=$261367.91, FE=0.0005, Loss=297.3024\n",
      "    TLT: 27.0%\n",
      "    QQQ: 22.9%\n",
      "    IWM: 16.1%\n",
      "  Step 5000: PV=$261367.91, FE=0.0005, Loss=297.3024\n",
      "    TLT: 27.0%\n",
      "    QQQ: 22.9%\n",
      "    IWM: 16.1%\n",
      "\n",
      "=== RISK-SEEKING AGENT ===\n",
      "Risk Lambda: -0.5\n",
      "  Step 0: PV=$54.78, FE=-0.0389, Loss=0.5249\n",
      "    cash: 80.2%\n",
      "    DIA: 19.8%\n",
      "\n",
      "=== RISK-SEEKING AGENT ===\n",
      "Risk Lambda: -0.5\n",
      "  Step 0: PV=$54.78, FE=-0.0389, Loss=0.5249\n",
      "    cash: 80.2%\n",
      "    DIA: 19.8%\n",
      "  Step 1000: PV=$23024.89, FE=-0.0555, Loss=141.3117\n",
      "    cash: 52.3%\n",
      "    GLD: 16.4%\n",
      "    IWM: 13.9%\n",
      "  Step 1000: PV=$23024.89, FE=-0.0555, Loss=141.3117\n",
      "    cash: 52.3%\n",
      "    GLD: 16.4%\n",
      "    IWM: 13.9%\n",
      "  Step 2000: PV=$65450.38, FE=-0.0262, Loss=90.9830\n",
      "    cash: 44.2%\n",
      "    QQQ: 19.6%\n",
      "    GLD: 11.7%\n",
      "  Step 2000: PV=$65450.38, FE=-0.0262, Loss=90.9830\n",
      "    cash: 44.2%\n",
      "    QQQ: 19.6%\n",
      "    GLD: 11.7%\n",
      "  Step 3000: PV=$99018.86, FE=-0.0138, Loss=132.8963\n",
      "    cash: 49.7%\n",
      "    QQQ: 24.4%\n",
      "    IWM: 15.4%\n",
      "  Step 3000: PV=$99018.86, FE=-0.0138, Loss=132.8963\n",
      "    cash: 49.7%\n",
      "    QQQ: 24.4%\n",
      "    IWM: 15.4%\n",
      "  Step 4000: PV=$145811.88, FE=-0.0087, Loss=294.7479\n",
      "    cash: 44.6%\n",
      "    TLT: 15.1%\n",
      "    GLD: 12.6%\n",
      "  Step 4000: PV=$145811.88, FE=-0.0087, Loss=294.7479\n",
      "    cash: 44.6%\n",
      "    TLT: 15.1%\n",
      "    GLD: 12.6%\n",
      "  Step 5000: PV=$231621.46, FE=-0.0097, Loss=297.3431\n",
      "    QQQ: 23.0%\n",
      "    TLT: 19.8%\n",
      "    GLD: 18.1%\n",
      "  Step 5000: PV=$231621.46, FE=-0.0097, Loss=297.3431\n",
      "    QQQ: 23.0%\n",
      "    TLT: 19.8%\n",
      "    GLD: 18.1%\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "================================================================================\n",
      "Data Period: 2004-11-18 to 2025-07-08\n",
      "Assets: QQQ, SPY, IWM, DIA, GLD, TLT\n",
      "Simulation Steps: 10,000\n",
      "--------------------------------------------------------------------------------\n",
      "Strategy        Final PV     Return %   Total Invested \n",
      "------------------------------------------------------------\n",
      "Equal Allocation $538565.50   278.8     $142164.38     \n",
      "Risk-Averse     $288193.38   102.7     $142164.38     \n",
      "Risk-Neutral    $269223.53   89.4      $142164.38     \n",
      "Risk-Seeking    $251711.27   77.1      $142164.38     \n",
      "\n",
      "================================================================================\n",
      "DETAILED PORTFOLIO COMPOSITIONS\n",
      "================================================================================\n",
      "\n",
      "EQUAL ALLOCATION STRATEGY:\n",
      "Final Portfolio Value: $538565.50\n",
      "Asset Allocation:\n",
      "  QQQ: 347.207622 shares, $191776.67 (35.6%)\n",
      "  SPY: 169.250738 shares, $104993.01 (19.5%)\n",
      "  DIA: 198.611191 shares, $87861.62 (16.3%)\n",
      "  GLD: 222.935862 shares, $67808.17 (12.6%)\n",
      "  IWM: 290.149807 shares, $64195.64 (11.9%)\n",
      "  TLT: 248.248613 shares, $21356.83 (4.0%)\n",
      "\n",
      "RISK-AVERSE STRATEGY:\n",
      "Final Portfolio Value: $288193.38\n",
      "Asset Allocation:\n",
      "  DIA: 165.624616 shares, $73269.02 (25.4%)\n",
      "  QQQ: 130.105909 shares, $71862.70 (25.0%)\n",
      "  SPY: 91.401250 shares, $56699.85 (19.7%)\n",
      "  IWM: 162.419270 shares, $35935.26 (12.5%)\n",
      "  TLT: 267.577349 shares, $23019.68 (8.0%)\n",
      "  GLD: 72.404626 shares, $22022.59 (7.6%)\n",
      "  CASH: $5110.25 (1.8%)\n",
      "\n",
      "RISK-NEUTRAL STRATEGY:\n",
      "Final Portfolio Value: $269223.53\n",
      "Asset Allocation:\n",
      "  QQQ: 107.409277 shares, $59326.44 (22.1%)\n",
      "  TLT: 681.483278 shares, $58628.01 (21.8%)\n",
      "  DIA: 113.962538 shares, $50414.75 (18.8%)\n",
      "  SPY: 57.049523 shares, $35390.10 (13.2%)\n",
      "  GLD: 110.278907 shares, $33542.43 (12.5%)\n",
      "  IWM: 136.757975 shares, $30257.70 (11.3%)\n",
      "  CASH: $1272.30 (0.5%)\n",
      "\n",
      "RISK-SEEKING STRATEGY:\n",
      "Final Portfolio Value: $251711.27\n",
      "Asset Allocation:\n",
      "  IWM: 430.492325 shares, $95246.43 (37.8%)\n",
      "  GLD: 127.651590 shares, $38826.51 (15.4%)\n",
      "  QQQ: 66.454306 shares, $36705.37 (14.6%)\n",
      "  DIA: 68.569031 shares, $30333.57 (12.0%)\n",
      "  SPY: 37.374083 shares, $23184.64 (9.2%)\n",
      "  TLT: 234.073250 shares, $20137.32 (8.0%)\n",
      "  CASH: $7393.09 (2.9%)\n",
      "\n",
      "================================================================================\n",
      "SIMULATION COMPLETED\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "================================================================================\n",
      "Data Period: 2004-11-18 to 2025-07-08\n",
      "Assets: QQQ, SPY, IWM, DIA, GLD, TLT\n",
      "Simulation Steps: 10,000\n",
      "--------------------------------------------------------------------------------\n",
      "Strategy        Final PV     Return %   Total Invested \n",
      "------------------------------------------------------------\n",
      "Equal Allocation $538565.50   278.8     $142164.38     \n",
      "Risk-Averse     $288193.38   102.7     $142164.38     \n",
      "Risk-Neutral    $269223.53   89.4      $142164.38     \n",
      "Risk-Seeking    $251711.27   77.1      $142164.38     \n",
      "\n",
      "================================================================================\n",
      "DETAILED PORTFOLIO COMPOSITIONS\n",
      "================================================================================\n",
      "\n",
      "EQUAL ALLOCATION STRATEGY:\n",
      "Final Portfolio Value: $538565.50\n",
      "Asset Allocation:\n",
      "  QQQ: 347.207622 shares, $191776.67 (35.6%)\n",
      "  SPY: 169.250738 shares, $104993.01 (19.5%)\n",
      "  DIA: 198.611191 shares, $87861.62 (16.3%)\n",
      "  GLD: 222.935862 shares, $67808.17 (12.6%)\n",
      "  IWM: 290.149807 shares, $64195.64 (11.9%)\n",
      "  TLT: 248.248613 shares, $21356.83 (4.0%)\n",
      "\n",
      "RISK-AVERSE STRATEGY:\n",
      "Final Portfolio Value: $288193.38\n",
      "Asset Allocation:\n",
      "  DIA: 165.624616 shares, $73269.02 (25.4%)\n",
      "  QQQ: 130.105909 shares, $71862.70 (25.0%)\n",
      "  SPY: 91.401250 shares, $56699.85 (19.7%)\n",
      "  IWM: 162.419270 shares, $35935.26 (12.5%)\n",
      "  TLT: 267.577349 shares, $23019.68 (8.0%)\n",
      "  GLD: 72.404626 shares, $22022.59 (7.6%)\n",
      "  CASH: $5110.25 (1.8%)\n",
      "\n",
      "RISK-NEUTRAL STRATEGY:\n",
      "Final Portfolio Value: $269223.53\n",
      "Asset Allocation:\n",
      "  QQQ: 107.409277 shares, $59326.44 (22.1%)\n",
      "  TLT: 681.483278 shares, $58628.01 (21.8%)\n",
      "  DIA: 113.962538 shares, $50414.75 (18.8%)\n",
      "  SPY: 57.049523 shares, $35390.10 (13.2%)\n",
      "  GLD: 110.278907 shares, $33542.43 (12.5%)\n",
      "  IWM: 136.757975 shares, $30257.70 (11.3%)\n",
      "  CASH: $1272.30 (0.5%)\n",
      "\n",
      "RISK-SEEKING STRATEGY:\n",
      "Final Portfolio Value: $251711.27\n",
      "Asset Allocation:\n",
      "  IWM: 430.492325 shares, $95246.43 (37.8%)\n",
      "  GLD: 127.651590 shares, $38826.51 (15.4%)\n",
      "  QQQ: 66.454306 shares, $36705.37 (14.6%)\n",
      "  DIA: 68.569031 shares, $30333.57 (12.0%)\n",
      "  SPY: 37.374083 shares, $23184.64 (9.2%)\n",
      "  TLT: 234.073250 shares, $20137.32 (8.0%)\n",
      "  CASH: $7393.09 (2.9%)\n",
      "\n",
      "================================================================================\n",
      "SIMULATION COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Strategy Comparison: Equal Allocation vs 3 Risk Profiles\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE PORTFOLIO STRATEGY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Data Period: {price_data.index[0].strftime('%Y-%m-%d')} to {price_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Assets: {', '.join(tickers)}\")\n",
    "print(f\"Annual Investment: $10,000 (${10000/365:.2f} per day)\")\n",
    "print(f\"Total Steps: 10,000 (with updates every 1,000 steps)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create agents with different risk sensitivities\n",
    "agent_neutral = ActiveInferenceAgent(state_dim=len(s0), n_assets=len(tickers), risk_lambda=0.0)\n",
    "agent_averse = ActiveInferenceAgent(state_dim=len(s0), n_assets=len(tickers), risk_lambda=1.0)\n",
    "agent_seeking = ActiveInferenceAgent(state_dim=len(s0), n_assets=len(tickers), risk_lambda=-0.5)\n",
    "\n",
    "def simulate_equal_allocation_strategy(env, max_steps=10000, update_interval=1000):\n",
    "    \"\"\"Equal allocation baseline: split daily investment equally across all assets\"\"\"\n",
    "    state = env.reset()\n",
    "    pv_history = []\n",
    "    daily_investment = env.daily_cash\n",
    "    n_assets = len(env.tickers)\n",
    "    total_invested = 0\n",
    "    \n",
    "    print(f\"\\n=== EQUAL ALLOCATION STRATEGY ===\")\n",
    "    print(f\"Daily allocation per asset: ${daily_investment/n_assets:.2f}\")\n",
    "    \n",
    "    for t in range(min(len(price_data) - 1, max_steps)):\n",
    "        # Add daily investment\n",
    "        env.cash += daily_investment\n",
    "        total_invested += daily_investment\n",
    "        \n",
    "        # Current prices\n",
    "        if env.step_idx < len(env.p):\n",
    "            prices = env.p.iloc[env.step_idx].values\n",
    "            \n",
    "            # Split available cash equally across all assets\n",
    "            cash_per_asset = env.cash / n_assets\n",
    "            \n",
    "            for i in range(n_assets):\n",
    "                if prices[i] > 0:\n",
    "                    shares_to_buy = cash_per_asset / (prices[i] * (1 + env.tc))\n",
    "                    cost = shares_to_buy * prices[i] * (1 + env.tc)\n",
    "                    if cost <= env.cash:\n",
    "                        env.hold[i] += shares_to_buy\n",
    "                        env.cash -= cost\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        if env.step_idx < len(env.p):\n",
    "            prices = env.p.iloc[env.step_idx].values\n",
    "            env.pv = env.cash + (env.hold * prices).sum()\n",
    "        \n",
    "        pv_history.append(env.pv)\n",
    "        \n",
    "        # Status update\n",
    "        if t % update_interval == 0:\n",
    "            comp = env.get_portfolio_composition()\n",
    "            print(f\"  Step {t}: PV=${env.pv:.2f}, Total Invested=${total_invested:.2f}\")\n",
    "            # Show top 3 allocations\n",
    "            top_assets = sorted(comp.items(), key=lambda x: x[1]['percentage'], reverse=True)[:3]\n",
    "            for asset, info in top_assets:\n",
    "                if asset != 'cash' or info['percentage'] > 5:\n",
    "                    print(f\"    {asset}: {info['percentage']:.1f}%\")\n",
    "        \n",
    "        env.step_idx += 1\n",
    "        if env.step_idx >= len(env.p) - 1:\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'portfolio_values': pv_history,\n",
    "        'final_pv': env.pv,\n",
    "        'final_composition': env.get_portfolio_composition(),\n",
    "        'total_invested': total_invested\n",
    "    }\n",
    "\n",
    "def simulate_active_inference_agent(agent, env, name, max_steps=10000, update_interval=1000):\n",
    "    \"\"\"Simulate Active Inference agent with specified risk profile\"\"\"\n",
    "    state = env.reset()\n",
    "    pv_history = []\n",
    "    fe_history = []\n",
    "    loss_history = []\n",
    "    \n",
    "    print(f\"\\n=== {name.upper()} AGENT ===\")\n",
    "    print(f\"Risk Lambda: {agent.risk_lambda}\")\n",
    "    \n",
    "    for t in range(min(len(price_data) - 1, max_steps)):\n",
    "        # Get agent action\n",
    "        actions = agent.act(state, t)\n",
    "        \n",
    "        # Calculate free energy for monitoring\n",
    "        latents = agent.infer(state)\n",
    "        fe = agent.expected_free_energy(latents, actions[0], t).item()\n",
    "        \n",
    "        # Step environment\n",
    "        next_state, reward, done, _ = env.step(actions)\n",
    "        \n",
    "        # Update agent beliefs\n",
    "        loss = agent.update_beliefs(state, actions, next_state, reward)\n",
    "        \n",
    "        # Record metrics\n",
    "        pv_history.append(env.pv)\n",
    "        fe_history.append(fe)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        # Status update\n",
    "        if t % update_interval == 0:\n",
    "            comp = env.get_portfolio_composition()\n",
    "            print(f\"  Step {t}: PV=${env.pv:.2f}, FE={fe:.4f}, Loss={loss:.4f}\")\n",
    "            # Show top 3 allocations\n",
    "            top_assets = sorted(comp.items(), key=lambda x: x[1]['percentage'], reverse=True)[:3]\n",
    "            for asset, info in top_assets:\n",
    "                if asset != 'cash' or info['percentage'] > 5:\n",
    "                    print(f\"    {asset}: {info['percentage']:.1f}%\")\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'portfolio_values': pv_history,\n",
    "        'free_energies': fe_history,\n",
    "        'losses': loss_history,\n",
    "        'final_pv': env.pv,\n",
    "        'final_composition': env.get_portfolio_composition()\n",
    "    }\n",
    "\n",
    "# Run all simulations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING SIMULATIONS...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Equal allocation baseline\n",
    "env.reset()\n",
    "results_equal = simulate_equal_allocation_strategy(env, max_steps=10000, update_interval=1000)\n",
    "\n",
    "# Risk-averse agent\n",
    "env.reset()\n",
    "results_averse = simulate_active_inference_agent(agent_averse, env, \"Risk-Averse\", max_steps=10000, update_interval=1000)\n",
    "\n",
    "# Risk-neutral agent\n",
    "env.reset()\n",
    "results_neutral = simulate_active_inference_agent(agent_neutral, env, \"Risk-Neutral\", max_steps=10000, update_interval=1000)\n",
    "\n",
    "# Risk-seeking agent\n",
    "env.reset()\n",
    "results_seeking = simulate_active_inference_agent(agent_seeking, env, \"Risk-Seeking\", max_steps=10000, update_interval=1000)\n",
    "\n",
    "# Final Results Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Data Period: {price_data.index[0].strftime('%Y-%m-%d')} to {price_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Assets: {', '.join(tickers)}\")\n",
    "print(f\"Simulation Steps: 10,000\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "strategies = [\n",
    "    (\"Equal Allocation\", results_equal),\n",
    "    (\"Risk-Averse\", results_averse),\n",
    "    (\"Risk-Neutral\", results_neutral),\n",
    "    (\"Risk-Seeking\", results_seeking)\n",
    "]\n",
    "\n",
    "# Print performance summary\n",
    "print(f\"{'Strategy':<15} {'Final PV':<12} {'Return %':<10} {'Total Invested':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for strategy_name, results in strategies:\n",
    "    final_pv = results['final_pv']\n",
    "    \n",
    "    if 'total_invested' in results:\n",
    "        total_invested = results['total_invested']\n",
    "        return_pct = (final_pv - total_invested) / total_invested * 100\n",
    "        print(f\"{strategy_name:<15} ${final_pv:<11.2f} {return_pct:<9.1f} ${total_invested:<14.2f}\")\n",
    "    else:\n",
    "        # For AI agents, estimate based on daily investment\n",
    "        estimated_invested = 10000 / 365 * len(results['portfolio_values'])\n",
    "        return_pct = (final_pv - estimated_invested) / estimated_invested * 100\n",
    "        print(f\"{strategy_name:<15} ${final_pv:<11.2f} {return_pct:<9.1f} ${estimated_invested:<14.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED PORTFOLIO COMPOSITIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for strategy_name, results in strategies:\n",
    "    print(f\"\\n{strategy_name.upper()} STRATEGY:\")\n",
    "    print(f\"Final Portfolio Value: ${results['final_pv']:.2f}\")\n",
    "    \n",
    "    comp = results['final_composition']\n",
    "    print(\"Asset Allocation:\")\n",
    "    \n",
    "    # Sort by percentage\n",
    "    sorted_assets = sorted(comp.items(), key=lambda x: x[1]['percentage'], reverse=True)\n",
    "    \n",
    "    for asset, info in sorted_assets:\n",
    "        if info['percentage'] > 0.1:  # Only show assets with >0.1% allocation\n",
    "            if asset == 'cash':\n",
    "                print(f\"  {asset.upper()}: ${info['amount']:.2f} ({info['percentage']:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"  {asset}: {info['shares']:.6f} shares, ${info['value']:.2f} ({info['percentage']:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULATION COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7056d12",
   "metadata": {},
   "source": [
    "## 8. Conclusions & Next Steps\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "This notebook demonstrates a comprehensive **Active Inference** framework for portfolio management, incorporating several cutting-edge concepts:\n",
    "\n",
    "1. **Hyperbolic Discounting**: Following Paul Glimcher's work on temporal decision-making, we implement hyperbolic discounting in the expected free energy calculation, creating more realistic time preferences.\n",
    "\n",
    "2. **Risk Sensitivity**: The framework includes a risk penalty term (Î» * variance) in the expected free energy, allowing for different risk profiles between agents.\n",
    "\n",
    "3. **Belief Updating**: The agent continuously updates its beliefs about market dynamics through variational inference, learning both observation and transition models.\n",
    "\n",
    "4. **Expected Free Energy Minimization**: Actions are chosen to minimize expected free energy, balancing:\n",
    "   - **Extrinsic value** (reconstruction accuracy)\n",
    "   - **Epistemic value** (information gain)\n",
    "   - **Risk penalty** (uncertainty aversion)\n",
    "\n",
    "### Theoretical Foundations\n",
    "\n",
    "This implementation bridges **neuroscience** (Active Inference), **behavioral economics** (hyperbolic discounting), and **finance** (portfolio optimization), creating a biologically-plausible decision-making framework that Karl Friston would appreciate.\n",
    "\n",
    "The agent operates under the **Free Energy Principle**, where actions are selected to minimize surprise and maintain homeostasis - a principle that extends from cellular biology to financial decision-making.\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "1. **Hierarchical Active Inference**: Implement multi-scale temporal dynamics\n",
    "2. **Precision-Weighted Beliefs**: Add attention mechanisms for feature weighting  \n",
    "3. **Social Active Inference**: Include market sentiment and herding behaviors\n",
    "4. **Continuous Learning**: Online adaptation to regime changes\n",
    "5. **Multi-Objective Optimization**: Balance multiple financial objectives simultaneously\n",
    "\n",
    "### Applications\n",
    "\n",
    "This framework could be extended to:\n",
    "- **Algorithmic Trading**: Real-time market making and execution\n",
    "- **Risk Management**: Dynamic hedging and portfolio insurance\n",
    "- **Behavioral Finance**: Understanding investor psychology and biases\n",
    "- **Central Banking**: Monetary policy under uncertainty\n",
    "\n",
    "The Active Inference approach provides a principled, neurobiologically-inspired alternative to traditional RL methods in finance, offering better interpretability and theoretical grounding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c186c7",
   "metadata": {},
   "source": [
    "## 7. Visualization of Beliefs & Allocations\n",
    "\n",
    "- **Latent Beliefs** over time  \n",
    "- **Portfolio Value** & **Holdings** evolution  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
